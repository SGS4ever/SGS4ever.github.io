<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>计算机网络 on XR_G&#39;s Blog</title>
    <link>https://xrg.fj.cn/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/</link>
    <description>Recent content in 计算机网络 on XR_G&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 07 Feb 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://xrg.fj.cn/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>PcapPlusPlus使用记录（二、通过解析数据包实现会话分割）</title>
      <link>https://xrg.fj.cn/p/pcapplusplus%E4%BD%BF%E7%94%A8%E8%AE%B0%E5%BD%95%E4%BA%8C%E9%80%9A%E8%BF%87%E8%A7%A3%E6%9E%90%E6%95%B0%E6%8D%AE%E5%8C%85%E5%AE%9E%E7%8E%B0%E4%BC%9A%E8%AF%9D%E5%88%86%E5%89%B2/</link>
      <pubDate>Mon, 07 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://xrg.fj.cn/p/pcapplusplus%E4%BD%BF%E7%94%A8%E8%AE%B0%E5%BD%95%E4%BA%8C%E9%80%9A%E8%BF%87%E8%A7%A3%E6%9E%90%E6%95%B0%E6%8D%AE%E5%8C%85%E5%AE%9E%E7%8E%B0%E4%BC%9A%E8%AF%9D%E5%88%86%E5%89%B2/</guid>
      <description>前情提要 在 上一篇PCPP使用记录 中，我记录了PcapPlusPlus这个库的环境安装和简单使用，紧接着，就准备基于这个库来实现一些具体的、有用的功能了。
数据包解析 PCPP这个库将一个原始数据包解析为若干层，每一层的协议信息由一个变量来保存，我们可以自由读写这些解析后的数据。
一个 RawPacket 表示原始的字节流，也就是我们最开始从 pcap 文件中读进来的一个数据包，经过解析，可以将这个数据包拆分成我们熟悉的若干层数据！PCPP的一个特性是它不保存多个副本，而只是在同一个数据包上标记各层协议的起点，这些起点可以由上一层解析结果访问到。
示例 例如这个图中的解析结果，首先是数据链路层的 Ethernet Layer ，它可以看到所有原始数据；由 Ethernet Layer 层扣除它的头部数据，就是整个 IPv4 层的数据；而由 IPv4 层再继续解析，就是 UDP 层啦！这样层层递推，实际上跟学习计算机网络的时候对数据包的解析顺序差不多。
PCPP提供的数据包解析方法有两种，我们分别来看。
首先还是需要先创建一个 reader ，如果你还记得第一章的内容，那就很简单了：
#include &amp;lt;iostream&amp;gt; #include &amp;lt;IPv4Layer.h&amp;gt; #include &amp;lt;Packet.h&amp;gt; #include &amp;lt;PcapFileDevice.h&amp;gt; int main(int argc, char* argv[]) { // Part 1 // open a pcap file for reading pcpp::IFileReaderDevice* reader = pcpp::IFileReaderDevice::getReader(&amp;#34;test_file_1.pcap&amp;#34;); if (!reader) { std::cerr &amp;lt;&amp;lt; &amp;#34;Cannot determine reader for file type&amp;#34; &amp;lt;&amp;lt; std::endl; return 1; } if (!</description>
    </item>
    
    <item>
      <title>PcapPlusPlus使用记录（一、环境搭建&amp;简单使用）</title>
      <link>https://xrg.fj.cn/p/pcapplusplus%E4%BD%BF%E7%94%A8%E8%AE%B0%E5%BD%95%E4%B8%80%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8/</link>
      <pubDate>Sat, 05 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://xrg.fj.cn/p/pcapplusplus%E4%BD%BF%E7%94%A8%E8%AE%B0%E5%BD%95%E4%B8%80%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8/</guid>
      <description>简介 由于项目的需要，近期产生了一个需求：将一个 pacp 文件解析出来，然后尝试提取每个连接的各种统计数据，例如提取一个完整的TCP会话中的源IP、目的IP、源端口、目的端口、会话开始时间、会话结束时间、发送的数据包数量、发送的数据包总大小等等。
能够实现这一需求的库有很多，如python中的 scapy 、 dpkt ，C++中的 PcapPlusPlus 等，考虑到将来可能需要处理较大的 pcap 文件，以及C++相比于python在执行速度上的优势，我决定使用C++作为流量处理的语言；简单翻阅了一下 PcapPlusPlus的文档 ，我认为这个库的易用性能够满足我较低的水平，因此决定先实践一下再说。
预装依赖 从这里开始，我想将 PcapPlusPlus 简称为 PCPP ，方便文章的撰写之用 。
本文使用的环境是：Win10 + VisualStudio2019 。
要使用这个库，我们需要先安装一些依赖。
个人建议将这些依赖下载到同一个地方，方便管理！
安装 WinPcap开发者工具 或 Npcap SDK 。下载解压而已，很简单！我这边使用的是WinPcap 。 安装 pthread-win32工具 ，注意这里的链接跟PCPP文档里面的链接是不一样的！文档里面的URL协议是 ftp ，我下载的时候好像打不开的样子，就改为使用 https 了！ 可能还需要一个 Microsoft Visual C++ Redistributable 工具，从这里下下来的是个 exe 文件，我在后面的过程中 暂时没有用到 ！也就是说我还没运行过这个EXE，先下载下来而已！ 下载PcapPlusPlus 直接从 PcapPlusPlus v21.11 页面上把示例代码下载下来！我这边选用的是 windows-vs2019 这个压缩包！
到这一步，算上我们之前下载 并解压 的依赖，文件夹里面应该有这么多东西：
现有的文件 All right？进入刚才下载的VS2019文件夹里面，有个 ExampleProject ，打开之：
ExampleProject文件结构 没问题的话，就准备运行示例程序了！
运行示例程序 熟悉VS的朋友可能要迫不及待地把那个 .</description>
    </item>
    
    <item>
      <title>TCP加速技术简述</title>
      <link>https://xrg.fj.cn/p/tcp%E5%8A%A0%E9%80%9F%E6%8A%80%E6%9C%AF%E7%AE%80%E8%BF%B0/</link>
      <pubDate>Thu, 25 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://xrg.fj.cn/p/tcp%E5%8A%A0%E9%80%9F%E6%8A%80%E6%9C%AF%E7%AE%80%E8%BF%B0/</guid>
      <description>传输控制协议（TCP）是我们的老朋友了，它力求在不可靠的IP网络上实现可靠的数据传输，也就是使得数据包有序、无丢失和不重复，因此，引入了如校验、序号、确认、重传等机制。同时，这位老朋友也是比较负责任的，在网络拥挤时，为了不使情况雪上加霜，它引入了慢启动、拥塞避免等机制。
现在的网络世界中，我们日常进行的网页浏览、游戏、视频等活动都离不开TCP。随着网络的发展，网络上面承载的数据包越来越多，在为多数人所共享的广域网上，在人们上网的高峰期，网络会存在一定的拥塞，反映到我们的上网体验上，就是延迟和丢包。加载个网页要花掉十几秒、玩个王者荣耀时不时延迟200+、看视频卡顿等，除了设备的问题，恐怕网络拥塞难辞其咎。在这样的背景之下，TCP加速技术也就产生和发展了。
实际上，TCP加速也不是一个新的概念了，十几年前就有相关的研究，但是这一理念在现今的背景下显得较有意义，我们对其进行一些学习和实践，大概不算是浪费时间的。
两种方案 TCP加速可以从几个角度来进行分类，较为常见且易懂的是从加速方案的部署位置来分。如果只在客户/服务器的某一边来部署TCP加速，就叫做 单边加速 ，如果双方都要部署，就叫做 双边加速 。两种方案一般有不同的使用场景，单边加速常部署在服务端上，这样就能透明地提升用户的访问体验；双边加速常常是双方协商好的一套加速方案，因此不能做到透明，可以用在客户端和服务端都可控的场景中，比如在个人云服务器上运行着某项服务，此时可以在自己的客户端PC和服务端都部署TCP加速，来改善访问体验。
单边加速概述 单边加速方案只需要由客户或服务端的一方来部署，比较简单，且对对方是透明的。我们首先要知道TCP是怎么工作的：在 协议规定 的运行模式下，发送方的系统 产生和处理数据 、 把数据交给网卡 、网卡发送数据，接收方接收数据、把数据交给系统、处理数据。从这一套流程中，我们应该发现几个可以下手的地方，每个地方都尝试一下，我们对TCP加速的认识也就差不多了。
数据包处理优化 说是数据包处理优化，其实就是所谓的“网络性能优化”。这个概念跟TCP协议本身没有太多关系，主要是针对收发数据双方的硬件、操作系统等进行优化。
减少复制 按照上面说过的流程，发送方的系统要产生和处理数据，然后把数据交给网卡。这一步是一个复制的过程，也就是将数据从系统或者应用程序所在的内存空间复制了一份到网卡的内存空间。这一步是可以优化的，有下面这几种办法。
直接访问网卡存储空间 。这种方案取消了复制，而采用地址映射或直接访问的办法，相当于将网卡看作了操作系统的一部分。为了实现这种方案，网卡要具备一定的智能性，否则无法支持多应用的访问，也无法在合适的时机传递数据。
与网卡共享存储区域 。让网卡用DMA或其他什么方式来访问内核内存空间，比上面的方案简单一些，对网卡的要求少一些。
其他各种内存映射方案 。内存映射可以实现应用、网卡和内核三者的内存共享，无论是什么内存映射方案，核心都是减少复制。
减少中断 系统要把数据交给网卡，或者网卡收到数据要交给系统的时候，一般都会触发中断。操作系统处理中断是需要花费时间的，因此这一步也是可以优化的。
将异步触发变为轮询 。有些研究者将TCP/IP的处理放置到一台单独的设备上，这样，就可以将协议数据的收发处理由中断的方式改变为比较简单的系统轮询。轮询的频率是要仔细调整的，太慢则数据处理产生延迟，太快则系统负载过大。
中断合并 。中断合并就是将多个中断合并到一起处理，也就是不在每次收到数据时产生中断，而是在数据积累到一定的量时再产生一次中断。这种方案使得延迟跟报文长度有关系了，且在处理数据的时候可能一次处理了多个报文，应用程序的调度也受到一些影响。
增加单个报文的长度 。思想和中断合并是类似的，就是将报文数据积累到一定长度再发送。但这一步是交给上层协议来完成的，跟中断合并时有区别的。
报文过滤 。总会有一些报文是没意义的，比如一些广播数据、一些没用的UDP报文，这些数据直接交给网卡来过滤，就能够减少中断。
用户级传输协议 传统的协议处理是在用户空间内完成的，因此要减少复制，只能引入各种内存映射或共享的方案。人们可以在用户空间实现传输层的协议，节省了数据复制的时间。
TCP卸载引擎 将软件执行转移到硬件执行，一直是性能优化的不二法门。如果在网卡硬件上运行一些特殊的系统，使得数据处理等步骤直接由网卡完成，那末系统的负载就小了，执行起来就快了。
TCP卸载引擎的缺点是存在的，那就是网卡硬件性能的提升要与系统其他硬件保持同步，否则还是可能成为传输速度的瓶颈；当然，要在网卡上实现数据处理的系统，本身的硬件和软件的设计难度也是很大的。
协议细节优化 数据包处理优化实际上就是针对机器本身的“网络性能优化”，而协议细节的优化才真正关乎TCP协议本身。
拥塞控制优化 TCP的拥塞控制机制我们是熟悉的，那就是：慢启动、拥塞避免（加法增加、乘法减少）。其实在这两个机制的基础上，延伸出的快重传和快恢复也属于拥塞控制的优化，当然我们还要有更多的尝试。
针对拥塞状态的判断 。我们如何判断网络是否拥塞呢？TCP协议一般以超时和重复ACK为标准。超时意味着不仅自己的数据没有到达，对方的重复ACK也没有到达，网络的拥塞情况已经比较严重了，因此传统的处理方法是将发送窗口减到 1 ，阈值减半，重新开始慢启动。重复ACK意味着自己的数据没有到达，对方的ACK可以到达，网络的拥塞情况还不那么严重，因此传统的处理方法是将阈值减半，发送窗口减到阈值大小，重新加法增加。慢启动和加法增加都是保守的，对带宽不一定有充分的利用，尤其当网络出现了小波动的时候，如果误判为拥塞，就会导致传输速度骤降，而带宽空闲。
有若干种针对拥塞状态的判断方案，例如zetaTCP使用了动态学习的方法判断拥塞，过滤非拥塞情况引起的丢包现象，预判拥塞丢包的概率并基于这一概率直接重传。Fast TCP结合延迟信息反馈来判断拥塞，Westwood结合带宽测量的技术来判断拥塞。
参数调节 TCP协议的参数是指预先写好的、控制协议工作的一些参数，如用于进行拥塞避免的拥塞窗口阈值，用于传输数据的MTU，用于判断超时的超时时间等。针对这些参数进行仔细的调节，可以一定程度达到TCP加速的目的。
并行TCP 并行TCP的理念是将原本的一条TCP连接修改为多条TCP连接，将原本使用一条连接来传输的数据放在多条连接上传输。这种思路归根到底是对拥塞避免算法的改造，原本一条连接上的拥塞避免算法，其强度在改为多条连接之后得到了削弱。例如原本的拥塞窗口是 N ，改成 k 条连接之后就成了 kN ，每次在拥塞避免时还是只把阈值减少 N/2 ，对总的窗口的影响就没那么大了。
双边加速——以UDP Speeder为例 双边加速要求在客户端和服务端都部署相同的加速方案，常规思路是把复杂的TCP协议转化为私有的协议。使用私有协议，可以对数据包处理、重传/拥塞避免等机制进行调整，从而达到加速的目的。
以开源的 UDP Speeder 为例，该系统在客户-服务器之间架设了一条隧道，在隧道中传输的数据使用了前向纠错编码，使得数据即便在传输过程中产生了一些错误和丢失，也能通过冗余的编码数据来把原始数据恢复过来。</description>
    </item>
    
    <item>
      <title>TCP加速之环境搭建（WANem）</title>
      <link>https://xrg.fj.cn/p/tcp%E5%8A%A0%E9%80%9F%E4%B9%8B%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BAwanem/</link>
      <pubDate>Tue, 23 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://xrg.fj.cn/p/tcp%E5%8A%A0%E9%80%9F%E4%B9%8B%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BAwanem/</guid>
      <description>我们可能遇到这样的情景：有一些实验需要在广域网环境下（存在一定的延迟、丢包等）完成，但我们不希望花费成本去租借一台云服务器，只希望在虚拟机网络中模拟出广域网的环境，应该如何实现呢？
本文是TCP加速系列总结的一部分 ，我们希望完成TCP加速的实验，这时要求我们的实验环境不仅是一个广域网，还需要是一个存在 一定拥塞 、会发生 一定丢包 的广域网，这种情况下，如果我们不使用模拟环境，而使用真实服务器的话，实验效果就可能受到服务器地理位置、实验时间段等等因素的影响了。
好在，我们可以使用WANem这一稳定、易用的广域网模拟器来解决我们的问题。
简介 WANem基于iptables和tc（Traffic Control）实现，可以实现对网络延迟、丢包率、抖动、噪音等的模拟，使用者可以简单地设定并复现出某个特定的网络环境，因而逐渐替代软件仿真成为新一代的网络测试床。与之具备类似概念的工具有微软的Network Emulator for Windows Toolkit（NEWT）、Linux 2.6自带的Netem等。事实上，此前说的tc（Traffic Control）就是用来控制Netem工作的，因此可以理解为WANem是基于Netem所构建。
安装与访问 WANem类似于一台虚拟机，可以直接 下载 iso文件，并在VMWare中安装。Linux类型选择 其他Linux 64位 即可。
启动之后，可以使用DHCP获取IP，或者手动配置IP；虚拟机会要求你设置口令，你可以使用用户名 perc 和你设置的口令来远程登录到系统上。
成功启动之后，会出现 WANemControl@PERC&amp;gt; 的命令行提示符，使用 help 命令可以查看该命令行支持的命令。
一般来说，你现在就可以在另一台机器的浏览器上使用 http://&amp;lt;WANem IP&amp;gt;/WANem 来访问控制界面了（注意URL大小写）。假如你不知道WANem的IP地址，则使用 exit2shell 命令来返回到Linux命令行中，使用我们熟悉的 ip addr 命令就可以看到WANem的IP。
成功访问WANem 配置规则 首次进入控制界面时，我们看到的是WANem的 Basic Mode ，这个模式下，我们可以配置 带宽 和 延迟 。
点击导航栏中的 Advanced Mode 进入高级配置，我们看到如下的界面：
Advanced Mode 界面上已经将各项指标都标识得比较清楚了，因此不多费口舌解释。在上图中，我们已经写好了一条”延迟100ms、随机丢包率20%“的规则。
可以指定我们的规则的适用范围，如果你只希望你配置的规则在两台特定主机之间生效，那么就填写下图红框框出的一行，否则保留原样即可。
规则 使用 保存我们设置好的规则，即刻开始使用它吧。
我们的两台实验机器分别是 CentOS7 192.168.213.128 和 Ubuntu 192.168.213.129 ，WANem是 192.168.213.130 。</description>
    </item>
    
    <item>
      <title>DoS——拒绝服务攻击</title>
      <link>https://xrg.fj.cn/p/dos%E6%8B%92%E7%BB%9D%E6%9C%8D%E5%8A%A1%E6%94%BB%E5%87%BB/</link>
      <pubDate>Tue, 02 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://xrg.fj.cn/p/dos%E6%8B%92%E7%BB%9D%E6%9C%8D%E5%8A%A1%E6%94%BB%E5%87%BB/</guid>
      <description>网络安全理论复习开始了！
今天从最简单的开始，目标是在寒假期间整理完成《网络安全》这门课所涉及的知识。希望本系列文章能以清晰的思路将安全理论表述出来。
DoS Denial of Service，拒绝服务，是现代网络安全领域很常见的一种攻击。所谓拒绝服务，就是通过一系列手段使得原本正常运行的服务器无法再为用户的请求提供服务与应答，从而使目标业务停滞。
我们经常能看到拒绝服务的例子：使用”呼死你“软件不断地拨打某人的电话，则其他人正常呼叫的时候他永远是占线的状态；网络”水军“控评，正常的评论和留言就无法被看到；黄牛使用恶意的抢票软件抢占所有电影票，使得正常渠道无法获得``````
在计算机网络的世界中，拒绝服务攻击可以是非常粗暴的物理攻击：砸毁服务器、切断网线等；更为常见且稍微有点技术含量的是利用计算机本身的漏洞，构造恶意的网络请求来使目标系统崩溃、主机宕机、重启等。
下面介绍一些常见的DoS攻击手法。
Ping of Death Ping of Death（死亡之Ping）的原理是构造一个超大的IP包来使目标主机瘫痪。在详细解释这个手法之前，需要从ICMP协议入手，介绍Ping的基本知识。
ICMP 网际控制报文协议（ICMP）用于让主机或路由器报告差错和异常情况。ICMP报文包含在IP数据报中，作为IP数据报的数据部分，加上IP首部发送出去，因此，ICMP是一个网络层协议。
ICMP报文的种类有两种，ICMP差错报告报文和ICMP询问报文。
ICMP差错报告报文用于目标主机或到目标主机路径上的路由器向源主机报告差错和异常情况，共有5种类型：
终点不可达。 源点抑制。由于拥塞而丢弃数据报时，要求源主机减小发送速率。 时间超过。 参数问题。路由器或目的主机收到的数据报首部中有的字段不正确。 改变路由（重定向）。路由器把重定向信息发给主机，下一次使用更好的路由。 ICMP询问报文有4种类型：
回送请求和应答。主机向目标发送ICMP请求，如果途中没有异常，则目标收到消息后恢复ICMP响应、 时间戳请求和应答。测试来回一次的传输时间。主机填充原始时间戳，接收方受到后填充时间戳返回。 掩码地址请求和回答。 路由器询问和通告。 PING PING工作在应用层。它直接使用网络层的ICMP询问报文，而未使用传输层的TCP或UDP。如果一台主机能PING通另一台主机，证明至少存在着一条可用的物理通路。
Ping of Death 死亡之Ping攻击利用了计算机实现IP协议时存在的缺陷。早期操作系统处理IP分组时，只开辟了64KB的缓冲区用来存放收到的数据包。如果攻击者故意在ICMP Echo（即PING数据报）之后附加非常多的冗余信息，使最终的IP包的大小超过65535字节的上限，接收方在处理这么大的IP包时就会产生内存分配错误，引起系统崩溃、挂起或重启。
可以看到这种攻击的实现主要是由于IP协议栈的漏洞，那为什么叫做死亡之Ping呢？因为使用PING工具太容易完成这种攻击，以至于它也成为了这种攻击的首选武器。当然，除了PING之外的任何能够构造超大IP包的程序都能实现这个攻击。
Ping of Death攻击不好预防，因为IP存在分组机制，每个IP包看起来都非常正常。最好的办法是在系统实现层面进行完善，使内核不再对超过规定长度的包进行重组。
TearDrop 又是IP协议实现的问题。故事从IP分片讲起。
分片 我们知道，数据链路层的每个数据报能够承载的数据量是有上限的，这个上限称为最大传送单元（MTU）。因为IP数据报被封装在数据链路层的数据报中，因此链路层的MTU严格地限制着IP数据报的长度。IP包传送的路径上，有许许多多的链路，可能使用不同的链路层协议，而同时也可能有大小不一的MTU。当IP数据报的总长度大于链路MTU时，需要能够将IP数据报中的数据分装在两个或多个较小的IP数据报中，然后再作为链路层数据进行传送。这些较小的数据报称为片。
片在目的地网络层被重新组装。对于一大堆杂乱无章的片，我们如何正确地重装成一个个独立的IP数据报呢？
IP协议使用首部的标识、标志和片偏移字段来完成对片的重组。我们看看IP数据报的首部：
IP Header 第二行的标识字段占16位。它是一个计数器，每产生一个数据报就加一。分片时每个数据报片都复制一次标识号，以便能正确重装成原来的数据报。
标志位有3比特。实际上只有后面2个比特有意义。它们分别是：
MF位（More Fragment）。当MF = 1时，表示这个数据报后面还有后续的片；当MF = 0时表示这是最后一个片。 DF位（Don&amp;rsquo;t Fragment）。只有DF = 0时才允许将一个数据报分片。若DF = 1且数据报大小大于链路层的MTU，只能丢弃并发送ICMP错误信息。 片偏移占13位。既然一个数据报能被分成好几个小片，那么每个小片需要记录自己在原始数据报中的位置，否则怎么重组呢？片偏移的单位是8B，也就意味着除了最后一个片外，每个片中的有效载荷都是8的倍数（字节）。
Teardrop 该攻击的原理是向目标主机发送一些分片的IP报文，并故意将片偏移字段设置成错误的值（与上一片重叠或错开）。某些操作系统在处理这类分片的时候会出现系统崩溃、重启等现象。
这里主要以重叠为例。重叠是指第二片IP包的偏移量小于第一片的尾部，且算上第二片的长度也没有超过第一片的尾部。我认为更加准确的描述应该是IP分片的镶嵌，如下所示：
分片重叠（镶嵌） 这时，我们要求第二个分片的长度，如果使用len2 = end2 - end1来计算，就产生了一个负值。</description>
    </item>
    
    <item>
      <title>传输层协议——TCP</title>
      <link>https://xrg.fj.cn/p/%E4%BC%A0%E8%BE%93%E5%B1%82%E5%8D%8F%E8%AE%AEtcp/</link>
      <pubDate>Wed, 27 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://xrg.fj.cn/p/%E4%BC%A0%E8%BE%93%E5%B1%82%E5%8D%8F%E8%AE%AEtcp/</guid>
      <description>传输层 传输层的功能
从通信和信息处理的角度看，传输层向它上面的应用层提供通信服务，它属于面向通信部分的最高层，同时也是用户功能中的最低层。
实际上，传输层起到一个承上启下的作用。它之下的网络层、数据链路层、物理层被称为通信子网，其实现细节对用户是不可见的。
传输层的功能如下：
提供进程之间的逻辑通信（即端到端的通信）。进程间的逻辑通信是指本主机上运行的某个进程和对方主机上运行的某个进程进行通信。而与此相对的，网络层提供的是点到点的通信，指的是本主机与对方主机的通信。 复用和分用。多个进程可以使用同一个传输层协议封装自己的数据，而对方主机可以使用同样的协议正确解析这些数据，交付给正确的应用进程。 差错检测。传输层检测首部和数据部分的差错，而网络层只检查IP数据报的首部，不检查数据部分是否出错。 提供两种不同的传输协议，即面向连接的TCP和无连接的UDP。网络层无法同时实现两种协议（即要么使用面向连接的服务，如虚电路；要么只提供无连接的服务，如数据报）。 需要注意，在计算机网络层次结构中，网络层被认为是不可靠的服务，即网络层传输的数据可能出现丢失、混乱或重复，这些不可靠的问题需要由传输层来考虑解决。
端口的概念
网络层的数据交付是点到点的，也就是主机到主机的交付。当一个IP数据报到达了主机，如何判断这份数据报应该交给哪个进程呢？传输层引入了端口，每个进程与一个端口号绑定。主机把IP数据报解封，就能看到里面的传输层数据包，其包头中写明了目的端口，只需要把数据交付给对应于这个端口的进程即可。
结合IP和端口，就能唯一地标识一台主机上的一个进程，这就是Socket（套接字）：
套接字 = （主机IP地址， 端口号）
TCP TCP协议的特点
TCP是在不可靠的IP层之上实现的可靠的数据传输协议，它主要针对之前提及的网络层数据传输的丢失、混乱或重复问题，实现传输层上的可靠、有序、无丢失和不重复。
TCP的主要特点如下：
面向连接。 每条连接只能有两个端点，即一对一的。 可靠的交付服务，保证数据无差错、不丢失、不重复且有序。 全双工通信，即任何时刻双方都能进行数据的发送。为此，双方都应该设置发送缓存和接收缓存，用来临时存放双向通信的数据。 面向字节流。计算机网络中常见的一个问题是：面向字节和面向报文有什么区别？ 面向字节流是指TCP将应用程序交付下来的数据仅视为一连串的无结构的字节流，发送的时候按照TCP的规则进行发送，不会考虑保留原始数据的边界；而面向报文是指每次发送的数据作为一个报文，一个报文是一块有结构的数据。 TCP报文段
想要理解TCP的连接建立等等细节，认识其报头是必要的。TCP有固定的20B报头，变长字段配合填充字段使TCP报头长度始终是4B的整数倍。由于首部长度字段只有4位，故报头最长为15 * 4 = 60B
TCP报头格式如下：
TCP Header 每个字段的含义可以参见这篇文章。
TCP连接管理
TCP是面向连接的协议，每个TCP连接都有三个阶段：连接建立、数据传输和连接释放。TCP的连接管理就是使运输连接的建立和释放都能正常进行。
TCP连接的端口称为套接字（socket）或插口。连接采用C/S方式，主动发起连接的进程称为客户机（Client），被动等待连接的进程称为服务器（Server）。
连接的建立分为3个步骤，即三次握手：
TCP three-way-handshake 第一步：客户机向服务器发送一个报文段，该报文段不含应用层数据，首部中的SYN标志被置为1，且该报文段占用了一个随机序号seq=x。 第二步：服务器收到连接请求，如同意连接，就向客户机发回确认，并为该连接分配TCP缓存和变量。确认报文中SYN和ACK都置为1，seq是服务器选用的初始随机序号，ack表示期望收到的下一个客户机报文序号。 第三步：客户机接收到确认报文，也要为该连接分配缓存和变量，并回复确认。 完成三次握手之后，双方的应用进程在任何时刻都可以发送数据（全双工）。
注意这里的第二步握手，服务器在此步分配资源，那么如果客户端不回应第三步的确认报文，则服务器在原地忙等，过一段时间后才删除这些资源；如果快速发送大量的SYN包给特定服务器，将耗尽它的资源，使得正常的连接无法被建立，这就是典型的SYN Flood攻击。
三次握手的必要性：
进行三次握手是必要的。
从直觉进行理解：第一步握手是客户端向服务器发送数据，此时双方对信道的性质还不了解；第二步握手成功之后，客户端知道了服务器能够收到自己的数据，但服务器还不知道客户端能不能收到自己的数据；第三步握手成功之后，服务器知道客户端能收到自己的数据，可以开始通信。
进一步地，考虑以下这种两次握手的情况：
TCP 2-way-handshake-bug1 在第二步握手时，服务器回应的报文段没有被客户机收到，而此时服务器认为连接已经建立（因为对服务器来说第二步握手已经完成了），开始发送数据；服务器发送的数据到达客户机，但客户机并不知道自己的连接已经建立，这里的seq字段是违法的，丢弃这些包；服务器超时重传，客户端继续丢弃。
当然，对于客户机来说，连接迟迟无法建立，应当重新发送SYN包，而对于服务器来说，与这个客户端的连接已经存在了，故对后来的连接请求不予响应。
不妨再考虑下面这种情况：
TCP 2-way-handshake-bug2 当客户机发送一个SYN包，该请求在网络中某个节点长时间滞留，客户机超时之后认为报文丢失，重传一次请求，服务器收到之后建立连接，开始传输数据。
数据传输完毕之后双方断开连接，而此时，前一个滞留在网络中的连接请求到达服务器，服务器认为客户机又请求建立连接。此时，如果使用两次握手，服务器认为连接建立，而客户机实际上并没有发起连接请求，因此不予理睬，造成了服务器资源的浪费。
数据传输完成之后，需要断开连接。如果你有注意到上图中的FIN报文段，需要留心，那只是个断开连接的示意，其中并没有展现“四次挥手”的过程。
而真正的“四次挥手”过程如下图：
TCP 四次挥手 第一步：客户机打算关闭连接时，向服务器发送一个连接释放报文段，其中FIN标志位设置为1,同样占用一个序号即seq=x（这里的x与之前三次握手的x无关，只是一种表示）。此时发送FIN的一端不能再发送数据，但可以发送控制信息，可以接收数据。 第二步：服务器收到连接释放报文段之后发出确认。此时客户机到服务器方向的连接就释放了，但服务器还能发送数据，客户机仍要接收。 第三步：服务器数据也发送完毕，向客户机发出FIN=1的报文段。 第四步：客户机收到连接释放报文段后，发出确认。发出确认后连接还没有释放，必须等待计时器设置的时间2MSL后才进入关闭状态。 等待2MSL的必要性：</description>
    </item>
    
  </channel>
</rss>
