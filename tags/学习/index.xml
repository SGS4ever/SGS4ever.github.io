<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>学习 on XR_G&#39;s Blog</title>
    <link>https://xrg.fj.cn/tags/%E5%AD%A6%E4%B9%A0/</link>
    <description>Recent content in 学习 on XR_G&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 29 Aug 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://xrg.fj.cn/tags/%E5%AD%A6%E4%B9%A0/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>秋招 | 一些知识点</title>
      <link>https://xrg.fj.cn/p/%E7%A7%8B%E6%8B%9B-%E4%B8%80%E4%BA%9B%E7%9F%A5%E8%AF%86%E7%82%B9/</link>
      <pubDate>Sun, 29 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://xrg.fj.cn/p/%E7%A7%8B%E6%8B%9B-%E4%B8%80%E4%BA%9B%E7%9F%A5%E8%AF%86%E7%82%B9/</guid>
      <description>2021-07-20，正式拉开了秋招备战的序幕。
我一直以来都深以为然的一个句子是，人一能之，己百之；人十能之，己千之。果能此道矣，虽愚必明，虽柔必强。 这个句子的意思是，如果你的学习能力比不上他人，那就花费百倍的精力去学，能够做到这一点的人，即使是一个愚者，也能够明了很多的知识。
1 C++引用和指针的区别 这个问题出现在昨天的面试中，在此予以学习和记录。
指针： 指针是一个变量，用于保存另一个变量的地址。指针需要使用 * 来进行解引用，以获取它指向的内存地址上的内容。
引用： 引用是一个 已经存在 的变量的别名，实际上，引用也是通过存储变量的地址来进行实现的。
两者的区别有如下几点：
初始化的方式不同。指针可以先声明，后赋值；引用必须在声明的同时进行初始化，因为它必须作为一个已经存在的变量的别名。
重复赋值。指针可以重复赋值（当然，const指针不行），而引用一旦声明，就不可以重复赋值。
内存占用。指针在栈上有其独立的内存空间（32bit机器就占用4字节），而引用与它的初始变量共享同一个空间，虽然它还是会花掉一部分栈空间。
是否为空。指针可以设置为NULL，而引用不行（基于第一点和第二点区别）。
间接引用。指针可以有多重嵌套，而引用不行。
In Pointers, int a = 10; int *p; int **q; //it is valid. p = &amp;amp;a; q = &amp;amp;p; // Whereas in references, int &amp;amp;p = a; int &amp;amp;&amp;amp;q = p; //it is reference to reference, so it is an error. 可以使用一句话来概括两者在实际使用中的规律：只在万不得已的时候使用指针。一般来说，引用会用在一个类的public接口中，而指针运用在其内部。
以下编辑于2021-07-25
传引用比传指针安全。 因为不存在空引用，并且引用一旦被初始化为指向一个对象，就不会被改变为另一个对象的引用；而指针可能被改变为另一个对象。
即使声明为常量指针 const Type* ，仍可能为空指针，并且可能产生野指针，所以还是不安全。
Reference</description>
    </item>
    
    <item>
      <title>字节后端面经</title>
      <link>https://xrg.fj.cn/p/%E5%AD%97%E8%8A%82%E5%90%8E%E7%AB%AF%E9%9D%A2%E7%BB%8F/</link>
      <pubDate>Sat, 28 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://xrg.fj.cn/p/%E5%AD%97%E8%8A%82%E5%90%8E%E7%AB%AF%E9%9D%A2%E7%BB%8F/</guid>
      <description>谁能想到我一个安全专业的人会被后端开发岗捞起来呢 -_-||
按照火星公司的性格，上岸概率不大。这篇先作为draft，暂时不在博客上发表出来。
1 HTTPS的流程？ 比较easy的问题，算是看在我的安全经验上来送分的？
此前整理过这个问题 ☞ 秋招 | 一些知识点 (xr_g的博客) ，但是面试的时候稍微有点紧张，忘了一些细节。回答的是基于公钥密码的密钥交换（这个流程比较好记）；但实际上HTTPS还有基于ECDHE的密钥交换，当时记得不够清楚，也就没跟面试官讲了。
1.1 为什么HTTPS不用公钥加密通信？ 肯定是效率啊！
非对称加密的算法能够得到严谨的安全性证明，但是它的加解密效率比较低；对称加密算法在设计时就充分考虑了计算机硬件的运算优势，所以效率很高。因此，我们一般用非对称加密算法来进行密钥交换，使用交换后的密钥进行对称加密的通信。
2 听过加盐吗？ 在存储用户口令的时候，在口令后面附上一些与用户身份相关的值，然后再进行哈希。
这样做的好处是对于不同用户的相同口令，不会得到相同的哈希值，避免了撞库和暴力破解。
当时可没答出撞库和爆破，冷静下来才发现答得有多烂（悲）。
2.1 那一般取什么值来作为盐呢？ 呃，嗯，这个……
一般取跟用户身份相关的值？比如用户ID？
事后发现当时少说了一个随机值。
3 听过彩虹表？ 大概是预先计算一些明文的哈希值，然后对着得到的哈希值进行比较破解？
巴拉了半天，发现我说的其实就是哈希字典。
然而彩虹表不是这样的！详见 密码破解的利器——彩虹表（rainbow table） - 简书 (jianshu.com) 。
郁闷，又挂一题。
4 听过SYN攻击吗？ SYN Flood？好亲切！
TCP三次握手时，当服务端收到一个SYN，返回ACK+SYN的时候，就为本次连接分配了资源，即所谓的 半开连接 。
而客户端需要完成第三次握手之后，才分配连接资源。
假如有很多客户端，同时向服务端发送SYN，但不完成第三次握手，就会以自身很少的资源消耗、来占用服务端大量的连接资源，使得服务端无法接受其他正常客户端的连接。
4.1 如何防御呢？ 一般的WAF都能识别此类攻击。
此外，可以在服务端适当地缩减半开连接的超时时间，即更快地清除没用的半开连接（我在说什么艹）。
还有就是可以用代理服务器先接受连接，这类服务器一般可以针对SYN进行硬件上的优化，也可以通过一定的算法来识别SYN Flood（实在想不出识别的算法，含糊其辞了）。
正解：代理服务器没毛病，可以使用cookie源认证等办法来识别恶意客户端；还有主机上可以设置SYN Cache，先不为半开连接分配资源，等建立连接之后再从cache中取出半开连接的信息，分配资源。
亏我以前还整理过，真正要用的时候想不起来了 -_-||
DoS——拒绝服务攻击 (gitee.io)
5 TCP和UDP的区别？ 可以再八股一点？
TCP是面向连接的，字节流；UDP是无连接的，报文流。
编程实现上也有一些区别，但是我没用过UDP编程（我又在说什么）。
还有就是TCP的连接是可靠的，有一些办法来保证。
5.1 怎么保证TCP连接可靠？ 挖坑埋自己……
想不起来了。</description>
    </item>
    
    <item>
      <title>深信服面经-安全攻防工程师</title>
      <link>https://xrg.fj.cn/p/%E6%B7%B1%E4%BF%A1%E6%9C%8D%E9%9D%A2%E7%BB%8F-%E5%AE%89%E5%85%A8%E6%94%BB%E9%98%B2%E5%B7%A5%E7%A8%8B%E5%B8%88/</link>
      <pubDate>Sat, 21 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://xrg.fj.cn/p/%E6%B7%B1%E4%BF%A1%E6%9C%8D%E9%9D%A2%E7%BB%8F-%E5%AE%89%E5%85%A8%E6%94%BB%E9%98%B2%E5%B7%A5%E7%A8%8B%E5%B8%88/</guid>
      <description>安全攻防工程师一面，大概率是寄了，此前也没有遇到过这种难度的面试，稍作记录吧。
恶意样本的静态分析？
大致答了一些常见的，PE文件头的分析、文件哈希、符号表、反编译之后的控制流和数据流等。
如果针对内存驻留的恶意程序呢？
显然就是上一个问题的Plus版本。没有思路。面试官提醒我可以考虑内存的R/W/X属性。我就说可以检测可执行的内存段，然后根据这些内存段的内容去生成可执行代码的特征，送入机器学习模型进行检测。扯就完事了……
一个进程中如果有多个线程（比如100个），CPU只有4个核，怎么分配？
属于是多线程的一个小盲区，我知道Python由于GIL全局锁，多线程是假的多线程，不知道其他语言的情况。
git熟悉吗？分支是干啥的？
只在日常博客中用git，分支知道一点点，就是从主线上分出若干个分支，团队成员在上面开发，不影响主线版本，最后再合并起来。
多线程扫描的时候，流量可能很大，怎么进行控制，怎么能不把目标扫崩（扫描不能产生DoS的效果）？
我把这个问题提炼成并发流量的控制，进一步就是并发线程的控制。只要控制活跃的线程数量，就能达到控制流量的作用。
5.1. 那怎么控制线程的数量？
可能可以先起一个线程，以这个线程的流量为标准，根据我们设定的阈值来得出线程的最大活跃数量。
5.2. 但是在实际的环境中，你到达目标的流量可能跟你出口的流量相差很多，因为你的流量要到达目标，还要过公网环境？
但是我们只能控制和计算出口流量，所以只能以出口流量为标准啊。考虑公网环境的损失的话，可能可以按照出口流量的计算值，再稍微上调一些，作为阈值。
内心OS：瞎扯就完了。后来面试官建议可以去看看nmap的流量控制，这一点打算以后有空写个博客。
多个模块之间的解耦。举例如下：
有四个模块分别是：【端口发现】、【服务识别】、【Web模糊测试】、【POC测试】，模块之间相互作用，主程序如何将他们联系起来？
这题给我问懵了，开始瞎扯。
首先分析，这四个模块应该是串联的关系，即服务识别模块依赖端口发现的输出，这样就可以用生产者消费者的模型来把他们组织起来。由于我们并不需要前一个模块的完整输出，只需要前一个模块产生部分输出，后一个模块就可以开始工作了，所以可以用流水线的思路来组织。
进一步开始扯IOC，逆转控制，就是原本是一个模块来实例化另一个模块，但是这样他们就耦合在一起了，IOC就是引入一个第三方控制程序，由它来讲另一个模块的对象在合适的时机注入到模块中，各个模块就不需要在自己的代码中引用其他模块了。
然后扯到消息队列，可能上一个模块产生输出之后，就可以挂到下一个模块的消息队列上，唤醒下一个模块来开始工作。
然而消息队列的具体实现并不了解，就没有多讲。
聊了聊其他项目，还有啥问题没，over。
总体来说，整个面试的技术内容还是比较硬核，确实能够起到筛选人的作用。很多问题不一定要你会细节，脑洞够大就行；同时，你在安全领域的见识够不够丰富，也是能问出来的。
我个人的能力确实没有非常精的领域（毕竟本科是通识教育啊操），大概率是凉了。
但是相比之下，此前字节一面二面的问题全是八股，万年不变的那种，完事之后撕代码，筛人全靠算法，简直无语。被这种面试挂了，总比被算法挂了来得服气，整场体验能给个3.5分吧。</description>
    </item>
    
    <item>
      <title>进程间文件同步写</title>
      <link>https://xrg.fj.cn/p/%E8%BF%9B%E7%A8%8B%E9%97%B4%E6%96%87%E4%BB%B6%E5%90%8C%E6%AD%A5%E5%86%99/</link>
      <pubDate>Sun, 27 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://xrg.fj.cn/p/%E8%BF%9B%E7%A8%8B%E9%97%B4%E6%96%87%E4%BB%B6%E5%90%8C%E6%AD%A5%E5%86%99/</guid>
      <description>这段期间没学到任何完整的、值得记录的东西，因此好久没有更新博客了，凑巧中午一边喝大红袍一边搞出了一点东西，虽然不太完整，也不妨一记。
最近在捣鼓Windows下应用程序调用API的情况统计，思路是向指定的进程中注入DLL，钩取系统API，这样每次进程调用API的时候先执行我们的语句，向统计文件中写入一条调用信息。
由此，引出了一个问题：如果我们注入了多个进程，这些进程同时调用一个API的时候，都要往统计文件中写一条信息，如何保持它们的同步呢？
答案就是文件锁。
锁 互斥锁是操作系统用来保持进程间同步的一个关键工具，多个进程同时对一个对象执行操作的时候，要分清楚先后顺序，否则可能产生混乱。比如，一个进程1要向一个文件里面写入1 ~ 100的数，而进程2要向这个文件里面写入101 ~ 200的数，我们希望进程1写完之后再让进程2写，但是系统在执行进程调度的时候，是可能在进程1写到一半的时候将其挂起，转而去执行其他进程的。想一想有没有可能出现这种情况：进程1写到了50，系统将其挂起，去执行其他进程，其他进程执行完之后，系统不执行进程1，而是执行进程2，于是我们的文件中的数字就变成了1,2&amp;hellip;50,101,102&amp;hellip;
显然，这样的情况是可能出现但是绝对不符合需求的，我们要想办法避免它。
于是操作系统为我们提供了互斥锁，即一个进程对某个对象执行操作的时候，将这个对象锁定，这时其他的进程就无法对这个对象执行操作了。
本篇中的文件锁其实就是作用在文件上的互斥锁。还是刚才的例子，如果进程1在一开始就为文件上了锁，当它执行到一半被挂起的时候，即使系统转为执行进程2，此时进程2也会因为无法获得文件锁而被阻塞；仅当进程1完成了写入，释放了文件锁，进程2才会被唤醒执行。
这样的工作模式可不止用来保持文件的读写同步，还可以解决一系列的同步问题。锁的思想在操作系统领域是非常重要的，这里的介绍不够全面，主要也是由于笔者目前的水平不够，有兴趣的朋友可以自行深入了解。
创建文件 初步了解了文件锁的含义之后，就要进入编码实践了。本篇后续编码是以C++为主体，但是核心部分完全兼容C语言。
首先要明确一点，C++的文件流操作无法实现文件锁。这个是笔者目前的水平下得出的结论，欢迎见多识广的读者在评论区批评指正。
既然无法使用fstream实现文件锁，就必须老老实实使用C语言的文件操作了。
在这里，由于WindowsAPI提供的文件锁函数需要一个HANDLE类型作为参数，我们只能使用CreateFile函数去创建文件了。
该API详见此文档。
我们使用以下两句话创建了一个文件，这里文件路径可以自由定义。
const char* logPath = &amp;#34;C:\\Users\\Administrator\\Desktop\\recLog.txt&amp;#34;; HANDLE hFile = ::CreateFileA( logPath, GENERIC_WRITE, FILE_SHARE_WRITE, 0, OPEN_ALWAYS, 0, 0 ); 值得注意的是CreateFileA的参数OPEN_ALWAYS，该参数指定了文件的打开方式：当文件不存在时，创建它；当文件存在时，打开它。
文件上锁 文件创建完成之后，正常的下一步操作应该是写入了。但是谨记，为了不发生开头提到的进程同步问题，我们要在写入文件之前先拿到文件的锁。这里使用Windows提供的一个关键函数LockFileEx()。
该API详见此文档
我们使用以下几句话为文件上了个锁，这里的overlapped变量是API要求我们传入的，没有很大的用处，将其置零即可。
OVERLAPPED overlapped; memset(&amp;amp;overlapped, 0, sizeof(overlapped)); const int lockSize = 10000;	// 上锁的字节数，没有很大的意义，非零即可。 if (!LockFileEx(hFile, LOCKFILE_EXCLUSIVE_LOCK, 0, lockSize, 0, &amp;amp;overlapped)) { DWORD err = GetLastError(); printf(&amp;#34;Error %i\n&amp;#34;, err); } 当文件上锁失败，if判断会成立，进入错误处理环节。记住开头提到的锁的机制，当一个进程无法获取当前的文件锁的时候，它应该是会被阻塞而非直接报错。在我的试验中，进入这个分支的情况是第一步CreateFile的时候得到了一个无效的句柄，而非无法获取当前文件的锁。</description>
    </item>
    
  </channel>
</rss>
